\documentclass[11pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb}
\usepackage{geometry}
\geometry{margin=2.5cm}
\usepackage{hyperref}
\usepackage{enumitem}
\usepackage{booktabs}
\usepackage{array}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{listings}
\usepackage{caption}

\lstset{
  language=Python,
  basicstyle=\ttfamily\small,
  keywordstyle=\color{blue},
  commentstyle=\color{gray},
  breaklines=true,
  frame=single,
  numbers=left,
  numberstyle=\tiny\color{gray},
}

\title{GNN-Based Antenna Array Clustering\\[6pt]
\large Cell-by-Cell Explanation of \texttt{gnn.ipynb}}
\author{}
\date{}

\begin{document}
\maketitle
\tableofcontents
\newpage

% ============================================================
\section{Problem Statement}
% ============================================================

\subsection{What Is the Physical Setup?}

We have a \textbf{Uniform Rectangular Array (URA)} of $16 \times 16 = 256$ antenna elements
operating at $29.5\;\text{GHz}$ (millimeter-wave, 5G NR band).
The elements are spaced $0.5\lambda$ apart horizontally and $0.7\lambda$ apart vertically,
where $\lambda = c / f \approx 1.017\;\text{cm}$.

In a phased array, each antenna element needs its own phase-shifter and RF chain.
With 256 elements, this is expensive.
\textbf{Clustering} (also called sub-arraying) groups nearby elements so that all elements
in the same cluster share a single phase-shifter.
This drastically reduces hardware cost: instead of 256 independent RF chains, we only need
$K$ clusters (where $K$ is automatically discovered by the GNN to achieve a target
clustering factor).

\subsection{What Do We Want to Optimize?}

The goal is to partition the 256 elements into clusters such that:
\begin{enumerate}[label=(\roman*)]
    \item \textbf{Target clustering factor is achieved}: the clustering factor
          $\text{CF} = N / K$ (average elements per cluster) is close to a specified target.
          The number of clusters $K$ is not fixed \emph{a priori}---the GNN discovers it
          automatically.
    \item \textbf{Clusters are spatially contiguous}: elements in the same cluster should be
          physically close (not scattered across the array).
    \item \textbf{Radiation performance is preserved}: the far-field pattern should maintain
          high main-lobe gain, low side-lobe levels (SLL), and narrow beamwidths (HPBW).
    \item \textbf{Cost function $C_m$ is minimized}: $C_m$ counts how many angular samples
          in the far-field pattern exceed a prescribed SLL mask---ideally $C_m = 0$.
\end{enumerate}

\subsection{How Do We Optimize?}

We use a \textbf{Graph Neural Network (GNN)} trained with \emph{unsupervised} loss functions
in a \emph{physics-informed} manner: mutual coupling between antenna elements is used as
edge weights in the graph.
The 256 antennas become \emph{nodes} of a graph; edges connect physically adjacent elements
and carry mutual coupling magnitudes.
The GNN learns a soft assignment matrix $\mathbf{Z} \in \mathbb{R}^{N \times K_{\max}}$
where $Z_{ik}$ is the probability that element $i$ belongs to cluster $k$, and $K_{\max}$
is an upper bound on the number of clusters.
The GNN automatically deactivates unused clusters, discovering the optimal $K$.
Hard assignments are obtained by $\text{cluster}(i) = \arg\max_k Z_{ik}$.

\subsection{Inputs and Outputs Summary}

\begin{center}
\renewcommand{\arraystretch}{1.3}
\begin{tabular}{p{3cm} p{10cm}}
\toprule
\textbf{Inputs} & 256 antenna positions on a $16\times16$ grid; spacing $d_x=0.5\lambda$,
$d_y=0.7\lambda$; frequency $29.5\;\text{GHz}$; target clustering factor $\text{CF}_{\text{target}}$;
beam steering direction $(\theta_0, \phi_0)$; SLL mask thresholds. \\
\midrule
\textbf{Optimization} & Physics-informed unsupervised GNN minimizing a composite loss
(coupling MinCut + clustering factor + entropy + contiguity).
Mutual coupling used as edge weights. No labelled data needed. \\
\midrule
\textbf{Outputs} & Cluster assignment vector $\mathbf{c} \in \{0,\dots,K{-}1\}^{256}$
where $K$ is automatically discovered;
far-field radiation pattern; performance metrics (gain, HPBW, SLL, $C_m$). \\
\bottomrule
\end{tabular}
\end{center}

\newpage
% ============================================================
\section{Cell-by-Cell Explanation}
% ============================================================

% ------------------------------------------------------------
\subsection{Cell 0 --- Title (Markdown)}
% ------------------------------------------------------------
A markdown header declaring the notebook title:
\emph{``GNN-based URA Clustering --- trains a Graph Neural Network to cluster a
$16\times16$ antenna array.''}
No code is executed.

% ------------------------------------------------------------
\subsection{Cell 1 --- Imports and Seeds}
% ------------------------------------------------------------

\textbf{What it does.}
Imports the required libraries and sets random seeds for reproducibility.

\begin{itemize}
    \item \texttt{numpy} --- numerical arrays and linear algebra.
    \item \texttt{torch} --- PyTorch deep learning framework (the GNN runs on PyTorch).
    \item \texttt{matplotlib} --- all plots.
    \item \texttt{sys.path.insert(0, '..')} --- adds the parent directory to Python's search
          path so that the custom \texttt{gnn} package (which lives one level up) can be imported.
    \item From the \texttt{gnn} package it imports:
    \begin{itemize}
        \item \texttt{URAConfig} --- a dataclass holding array geometry (rows, cols, spacing, frequency).
        \item \texttt{create\_ura\_graph} --- builds a graph from the antenna grid (nodes = elements,
              edges = neighbors), with mutual-coupling edge weights.
        \item \texttt{compute\_mutual\_coupling} --- computes an $N \times N$ complex coupling matrix
              using a simplified analytical model: $M_{ij} = e^{-j2\pi r_{ij}} / (r_{ij} + 0.1)$
              with edge/corner corrections.
        \item \texttt{train\_ura\_clustering} --- physics-informed training loop with target
              clustering factor. The GNN discovers the optimal number of clusters automatically.
        \item \texttt{assignments\_to\_antenna\_format} --- converts a flat cluster-label vector
              into the list-of-coordinate-arrays format expected by the antenna physics engine.
    \end{itemize}
    \item Sets \texttt{torch.manual\_seed(42)} and \texttt{np.random.seed(42)} so that every run
          produces the same results.
\end{itemize}

\textbf{Output.}
Prints the PyTorch version (2.9.1+cpu) and whether CUDA is available (False---training runs on CPU).

% ------------------------------------------------------------
\subsection{Cell 2 --- Section Header (Markdown)}
% ------------------------------------------------------------
Markdown: ``\textbf{1.\ Configuration}''. No code.

% ------------------------------------------------------------
\subsection{Cell 3 --- Array Configuration}
% ------------------------------------------------------------

\textbf{What it does.}
Creates a \texttt{URAConfig} object with the physical parameters of the antenna array:
\begin{itemize}
    \item \texttt{rows=16, cols=16} $\Rightarrow$ $N = 256$ elements.
    \item \texttt{dx=0.5} $\Rightarrow$ horizontal spacing = $0.5\lambda$ ($\approx 5.08\;\text{mm}$).
    \item \texttt{dy=0.7} $\Rightarrow$ vertical spacing = $0.7\lambda$ ($\approx 7.12\;\text{mm}$).
    \item \texttt{freq\_ghz=29.5} $\Rightarrow$ $f = 29.5\;\text{GHz}$, hence
          $\lambda = 3 \times 10^8 / 29.5 \times 10^9 \approx 1.017\;\text{cm}$.
\end{itemize}
Internally, \texttt{URAConfig} also computes \texttt{dx\_meters} and \texttt{dy\_meters}
(physical spacing in meters).

\textbf{Output.}
\begin{verbatim}
Array: 256 elements
Spacing: dx=0.5 lambda, dy=0.7 lambda
\end{verbatim}

% ------------------------------------------------------------
\subsection{Cell 4 --- Section Header (Markdown)}
% ------------------------------------------------------------
Markdown: ``\textbf{2.\ Train GNN (Physics-Informed)} --- Uses mutual coupling and targets a
clustering factor of $\sim$3.''

% ------------------------------------------------------------
\subsection{Cell 5 --- Train GNN (Physics-Informed)}
\label{sec:cell5}
% ------------------------------------------------------------

\textbf{What it does.}
Trains the GNN to partition 256 antennas into clusters using the physics-informed pipeline
with a target clustering factor of $\text{CF} = 3$.
The number of clusters $K$ is \emph{not} fixed---the GNN discovers it automatically.

\paragraph{Inside \texttt{train\_ura\_clustering}:}
\begin{enumerate}
    \item \textbf{Upper bound on clusters.}
          $K_{\max} = \min\bigl(N,\; \lfloor N / \text{CF}_{\text{target}} \times 1.5 \rfloor\bigr)$.
          The GNN outputs $K_{\max}$ soft clusters and deactivates unused ones during training.

    \item \textbf{Graph construction} (\texttt{create\_ura\_graph} with \texttt{use\_coupling=True}).
    \begin{itemize}
        \item Each of the 256 antennas becomes a \emph{node}.
              Its feature vector is its 2D position $(x, y)$ in wavelengths.
        \item Edges connect each element to its 8 grid neighbors (8-connected).
        \item The mutual coupling matrix $\mathbf{M} \in \mathbb{C}^{256 \times 256}$ is computed:
              $M_{ij} = \frac{e^{-j2\pi r_{ij}}}{r_{ij} + 0.1} \times f_{\text{edge}}$
              where $r_{ij}$ is the distance in wavelengths and $f_{\text{edge}}$ is a correction
              factor (0.85$\times$ for edge elements, additional 0.9$\times$ for corners).
        \item Each edge carries a feature vector $[\Delta x, \Delta y, d, |M_{ij}|]$ (4 components).
        \item The coupling-weighted adjacency $\mathbf{W} = |\mathbf{M}|$ is used in the MinCut loss.
    \end{itemize}

    \item \textbf{Position normalization.}
          All $(x,y)$ coordinates are min-max normalized to $[0, 1]$.

    \item \textbf{Model instantiation} (\texttt{URAClusteringGNN}).
    \begin{itemize}
        \item Architecture: \texttt{Linear(2$\to$64)} $\to$ \texttt{BatchNorm} $\to$ \texttt{ELU}
              $\to$ \texttt{GATConv}$_1$(64$\to$256, 4 heads) $\to$ \texttt{BatchNorm} $\to$ \texttt{ELU}
              $\to$ \texttt{GATConv}$_2$(256$\to$256, 4 heads) $\to$ \texttt{BatchNorm} $\to$ \texttt{ELU}
              $\to$ \texttt{GATConv}$_3$(256$\to$64, 1 head) $\to$ \texttt{ELU}
              $\to$ \texttt{Linear(64$\to K_{\max}$)} $\to$ \texttt{Softmax}.
        \item \texttt{GATConv} = Graph Attention Convolution. Each node aggregates features
              from its neighbors using learned attention weights.
              The attention mechanism lets the network learn which neighbors matter more.
        \item The final softmax outputs $\mathbf{Z} \in \mathbb{R}^{256 \times K_{\max}}$:
              a soft cluster-assignment matrix where $Z_{ik}$ is the probability that
              antenna $i$ belongs to cluster $k$.
    \end{itemize}

    \item \textbf{Loss function} (what we minimize). Four terms:
    \begin{enumerate}[label=\alph*)]
        \item \textbf{Coupling MinCut loss} (weight 1.0):
              \[
                  \mathcal{L}_{\text{cut}} = -\frac{\text{tr}(\mathbf{Z}^\top \mathbf{W}\, \mathbf{Z})}
                  {\text{tr}(\mathbf{Z}^\top \mathbf{D}\, \mathbf{Z})}
              \]
              where $\mathbf{W} = |\mathbf{M}|$ is the coupling-weighted adjacency matrix
              and $\mathbf{D} = \text{diag}(\mathbf{W}\,\mathbf{1})$.
              Minimizing this encourages the network to place \emph{strongly coupled} elements
              in the \emph{same} cluster.

        \item \textbf{Clustering factor loss} (weight $\lambda_{\text{cf}} = 10.0$):
              \[
                  \mathcal{L}_{\text{cf}} = \left(\frac{n_{\text{active}} - N / \text{CF}_{\text{target}}}
                  {N / \text{CF}_{\text{target}}}\right)^2
              \]
              where $n_{\text{active}} = \sum_{k=1}^{K_{\max}} \sigma\bigl(5 \cdot (s_k - 0.5)\bigr)$
              is the differentiable (sigmoid-based) count of active clusters,
              and $s_k = \sum_{i} Z_{ik}$ is the soft size of cluster $k$.
              This steers the GNN toward the desired average cluster size without
              fixing the number of clusters \emph{a priori}.

        \item \textbf{Entropy loss} (weight $\lambda_{\text{ent}} = 0.5$):
              \[
                  \mathcal{L}_{\text{ent}} = -\frac{1}{N}\sum_{i=1}^{N}\sum_{k=1}^{K} Z_{ik} \log Z_{ik}
              \]
              Encourages \emph{confident} assignments (low entropy $\Rightarrow$ each node is
              assigned to one cluster with high probability, not spread evenly).

        \item \textbf{Contiguity loss} (weight $\lambda_{\text{cont}} = 0.5$):
              \[
                  \mathcal{L}_{\text{cont}} = \frac{1}{K}\sum_{k=1}^{K}
                  \frac{\sum_{i} Z_{ik} \|\mathbf{p}_i - \boldsymbol{\mu}_k\|^2}{s_k}
              \]
              where $\boldsymbol{\mu}_k = \sum_i Z_{ik}\,\mathbf{p}_i \,/\, s_k$ is the soft
              centroid of cluster $k$. Penalizes fragmented clusters by encouraging spatial
              compactness.
    \end{enumerate}

    Total loss: $\mathcal{L} = \mathcal{L}_{\text{cut}}
    + 10 \cdot \mathcal{L}_{\text{cf}}
    + 0.5 \cdot \mathcal{L}_{\text{ent}}
    + 0.5 \cdot \mathcal{L}_{\text{cont}}$.

    \item \textbf{Optimizer:} AdamW (lr $= 0.001$, weight decay $= 10^{-4}$) with cosine
          annealing learning rate schedule, for 500 epochs.
          Gradient clipping with max norm $1.0$ for stability.

    \item \textbf{NaN recovery:} if NaN values are detected during training, the model is
          reinitialised and training continues from the current epoch.

    \item \textbf{Best checkpoint:} the cluster assignment with the lowest total loss
          seen during training is saved. If the final result is degenerate (single cluster),
          the best checkpoint is used instead.

    \item \textbf{Output:} After training, hard assignments are extracted:
          $\text{cluster}(i) = \arg\max_k Z_{ik}$.
          Cluster labels are relabelled to consecutive integers (gaps from empty clusters
          are removed).
\end{enumerate}

\textbf{Output.}
The training prints progress every 100 epochs, showing the total loss, number of active
clusters, current clustering factor, and cluster size statistics (min, max, mean).
The final output reports the discovered number of clusters and the achieved CF.

% ------------------------------------------------------------
\subsection{Cell 6 --- Section Header (Markdown)}
% ------------------------------------------------------------
Markdown: ``\textbf{3.\ Visualize Results}''.

% ------------------------------------------------------------
\subsection{Cell 7 --- Visualization}
% ------------------------------------------------------------

\textbf{What it does.}
Creates two side-by-side plots:

\begin{enumerate}
    \item \textbf{Scatter plot} (left): each antenna element is a dot at its physical $(x,y)$
          position, colored by cluster assignment.
          The colormap adapts to the number of active clusters discovered by the GNN
          (\texttt{nipy\_spectral} for $>20$, \texttt{tab20} for $>10$, \texttt{tab10} otherwise).

    \item \textbf{Grid view} (right): the cluster assignments reshaped into the $16 \times 16$ grid,
          displayed as a color-coded image.
          This is the ``bird's-eye view'' of which antenna belongs to which cluster.
\end{enumerate}

% ------------------------------------------------------------
\subsection{Cell 11 --- Section Header (Markdown)}
% ------------------------------------------------------------
Markdown: ``\textbf{5.\ Radiation Pattern (if available)}''.

% ------------------------------------------------------------
\subsection{Cell 12 --- Radiation Pattern Evaluation}
\label{sec:cell12}
% ------------------------------------------------------------

This is the largest and most important evaluation cell.
It defines helper functions and then computes the far-field radiation pattern
for the GNN clustering result.

\subsubsection{Helper function: \texttt{extract\_lobe\_metrics}}

\textbf{Input:} 2D far-field pattern $\text{FF\_I\_dB}[\theta, \phi]$ in dBi, the
azimuth/elevation angle vectors, the beam-steering direction $(\phi_0, \theta_0)$,
and the boresight gain.

\textbf{What it computes:}
\begin{itemize}
    \item Extracts the elevation cut (FF at fixed $\phi = \phi_0$) and azimuth cut
          (FF at fixed $\theta = \theta_0$).
    \item \textbf{HPBW} (Half-Power Beamwidth): finds the $-3\;\text{dB}$ crossing points
          around the main lobe peak in both cuts.
          Narrower HPBW means a more focused beam.
    \item \textbf{SLL} (Side-Lobe Level): identifies all local maxima (via \texttt{scipy.find\_peaks})
          that are $>3\;\text{dB}$ below the main lobe, and reports the highest one.
          Lower SLL means less power wasted in unwanted directions.
    \item \textbf{Number of lobes}: counts all peaks above $-30\;\text{dB}$.
\end{itemize}

\textbf{Output:} a dictionary with gain, HPBW, SLL, and lobe counts.

\subsubsection{Helper function: \texttt{plot\_lobe\_analysis}}

\textbf{Input:} the same pattern data plus the \texttt{AntennaArray} object.

\textbf{What it plots} (6-panel figure):
\begin{enumerate}
    \item Elevation cut (Cartesian) with $-3\;\text{dB}$ line and SLL marker.
    \item Azimuth cut (Cartesian) with $-3\;\text{dB}$ line and SLL marker.
    \item 2D contour map of the full far-field pattern (azimuth vs.\ elevation), with
          a star at the steering direction.
    \item Summary table of all metrics.
    \item Elevation pattern in polar coordinates.
    \item Azimuth pattern in polar coordinates.
\end{enumerate}

\subsubsection{Radiation evaluation pipeline}

The cell performs the following steps:
\begin{enumerate}
    \item \textbf{Format conversion} (\texttt{assignments\_to\_antenna\_format}):
          converts the flat vector $[0, 2, 1, 3, \ldots]$ into a list of $K$ arrays,
          each containing the lattice coordinates $(\text{NN}, \text{MM})$ of elements
          in that cluster.
          These lattice coordinates match the indexing convention used by the
          antenna physics engine.
          Empty clusters (if any) are automatically skipped.

    \item \textbf{Antenna array setup}: creates an \texttt{AntennaArray} object with:
    \begin{itemize}
        \item \texttt{LatticeConfig}: $16 \times 16$, spacing $(0.7\lambda, 0.5\lambda)$.
        \item \texttt{SystemConfig}: $f = 29.5\;\text{GHz}$, beam steered to
              $(\theta_0, \phi_0) = (0^\circ, 0^\circ)$, angular resolution
              $\Delta\theta = \Delta\phi = 0.5^\circ$.
        \item \texttt{MaskConfig}: SLL mask thresholds---defines the acceptable
              side-lobe levels inside and outside the field of view.
        \item \texttt{ElementPatternConfig}: $P=1$ means the element pattern is
              $\cos(\theta)\cos(\phi)$, element gain $G_{\text{el}} = 5\;\text{dBi}$.
    \end{itemize}

    \item \textbf{Radiation pattern computation} (\texttt{evaluate\_clustering}):
    \begin{enumerate}[label=\roman*)]
        \item Converts cluster coordinates to physical positions $(Y_c, Z_c)$ in meters.
        \item Computes cluster centroids $(Y_{c,m}, Z_{c,m})$.
        \item Computes excitation coefficients:
              $c_0^{(k)} = \frac{1}{L_k} \exp\!\bigl(-j(w_0 Z_{c,m}^{(k)} + v_0 Y_{c,m}^{(k)})\bigr)$
              where $w_0, v_0$ encode the steering direction and $L_k$ is the cluster size.
              Each cluster gets a single complex weight (amplitude $1/L_k$, phase for steering).
        \item Computes the array factor via the kernel:
              $\text{KerFF}(w,v) = \sum_{\text{elements}} F_{\text{el}}(w,v) \cdot e^{j(v \cdot Y + w \cdot Z)}$
              summed per cluster, then combined as $\text{FF} = \text{KerFF} \cdot c_0^\top$.
        \item Interpolates from $(w,v)$ spectral domain to $(\theta, \phi)$ angular domain.
        \item Adds element pattern gain: $\text{FF\_I\_dB} = \text{FF\_norm\_dB} + G_{\text{el,max}} + 10\log_{10}(N_{\text{active}})$.
        \item Computes $C_m$: counts how many angular samples exceed the SLL mask.
        \item Computes SLL in-FoV and out-of-FoV (excluding a $\pm10^\circ$ main-lobe exclusion zone).
    \end{enumerate}

    \item \textbf{Plots} the 6-panel lobe analysis figure.

    \item \textbf{Prints} the number of clusters, clustering factor, $C_m$,
          SLL out-of-FoV, and SLL in-FoV.
\end{enumerate}

\newpage
% ============================================================
\section{Test Cases (Cells 15--25)}
% ============================================================

The remaining cells implement 5 specific test cases to evaluate the GNN under different
steering directions, target clustering factors, and SLL constraints.
All cases share:
\begin{itemize}
    \item $f = 29.5\;\text{GHz}$, element pattern $\cos(\theta)\cos(\phi)$ ($P=1$).
    \item $N = 256$ ($16 \times 16$), spacing $d_y = 0.7\lambda$, $d_x = 0.5\lambda$.
    \item Physics-informed GNN mode (500 epochs), mutual coupling edge weights.
    \item The number of clusters $K$ is auto-discovered to achieve the target CF.
\end{itemize}

Each test case follows the \textbf{same pipeline}:
\begin{enumerate}
    \item Create \texttt{URAConfig} $\to$ train GNN with \texttt{target\_cf} $\to$ get cluster assignments.
    \item Create \texttt{AntennaArray} with case-specific steering and mask.
    \item Convert assignments $\to$ evaluate radiation $\to$ plot $\to$ print results.
    \item Save checkpoint to JSON.
\end{enumerate}

% ------------------------------------------------------------
\subsection{Case 1: $\theta=10^\circ$, $\phi=0^\circ$, target CF$=2$, SLL $< -20\;\text{dB}$}
% ------------------------------------------------------------

\begin{center}
\begin{tabular}{ll}
\toprule
\textbf{Parameter} & \textbf{Value} \\
\midrule
Beam steering & elevation $\theta_0 = 10^\circ$, azimuth $\phi_0 = 0^\circ$ \\
Target clustering factor & $\text{CF} = 2$ ($\approx 2$ elements/cluster) \\
SLL requirement & $< -20\;\text{dB}$ (both in-FoV and out-of-FoV) \\
FoV mask & elevation $\pm30^\circ$, azimuth $\pm60^\circ$ \\
\bottomrule
\end{tabular}
\end{center}

\textbf{What happens.}
With $\text{CF} = 2$, the GNN targets $\approx 128$ clusters of $\approx 2$ elements each.
This is close to the no-clustering case (each element independent), so
radiation performance should be near-optimal.
The beam is steered $10^\circ$ off boresight in elevation.

% ------------------------------------------------------------
\subsection{Case 2: $\theta=0^\circ$, $\phi=60^\circ$, target CF$=2$, SLL $< -20\;\text{dB}$}
% ------------------------------------------------------------

\begin{center}
\begin{tabular}{ll}
\toprule
\textbf{Parameter} & \textbf{Value} \\
\midrule
Beam steering & elevation $\theta_0 = 0^\circ$, azimuth $\phi_0 = 60^\circ$ \\
Target clustering factor & $\text{CF} = 2$ \\
SLL requirement & $< -20\;\text{dB}$ \\
\bottomrule
\end{tabular}
\end{center}

\textbf{What happens.}
The beam is steered to $60^\circ$ in azimuth---an extreme angle near the edge of the
field of view. This is the hardest steering case because the array factor degrades
at wide scan angles and grating lobes may appear (especially with $d_x = 0.5\lambda$).

% ------------------------------------------------------------
\subsection{Case 3: $\theta=10^\circ$, $\phi=45^\circ$, target CF$=4$, SLL $< -20\;\text{dB}$}
% ------------------------------------------------------------

\begin{center}
\begin{tabular}{ll}
\toprule
\textbf{Parameter} & \textbf{Value} \\
\midrule
Beam steering & elevation $\theta_0 = 10^\circ$, azimuth $\phi_0 = 45^\circ$ \\
Target clustering factor & $\text{CF} = 4$ ($\approx 4$ elements/cluster) \\
SLL requirement & $< -20\;\text{dB}$ \\
\bottomrule
\end{tabular}
\end{center}

\textbf{What happens.}
Diagonal steering---the beam points simultaneously off-axis in both elevation and azimuth.
With $\text{CF} = 4$, the GNN targets $\approx 64$ clusters.
This combines the challenges of Cases 1 and 2 with higher compression.

% ------------------------------------------------------------
\subsection{Case 4: $\theta=10^\circ$, $\phi=45^\circ$, target CF$=4$, SLL $< -15\;\text{dB}$}
% ------------------------------------------------------------

\begin{center}
\begin{tabular}{ll}
\toprule
\textbf{Parameter} & \textbf{Value} \\
\midrule
Beam steering & elevation $\theta_0 = 10^\circ$, azimuth $\phi_0 = 45^\circ$ \\
Target clustering factor & $\text{CF} = 4$ ($\approx 4$ elements/cluster) \\
SLL requirement & $< -15\;\text{dB}$ (relaxed) \\
\bottomrule
\end{tabular}
\end{center}

\textbf{What happens.}
Same steering and CF as Case~3, but with a relaxed SLL constraint ($-15\;\text{dB}$
instead of $-20\;\text{dB}$).
This tests whether the GNN can produce a useful clustering with higher compression
and relaxed requirements.

% ------------------------------------------------------------
\subsection{Case 5: $\theta=0^\circ$, $\phi=0^\circ$, target CF$=8$}
% ------------------------------------------------------------

\begin{center}
\begin{tabular}{ll}
\toprule
\textbf{Parameter} & \textbf{Value} \\
\midrule
Beam steering & boresight $\theta_0 = 0^\circ$, $\phi_0 = 0^\circ$ \\
Target clustering factor & $\text{CF} = 8$ ($\approx 8$ elements/cluster) \\
SLL requirement & $-20\;\text{dB}$ out-of-FoV, $-15\;\text{dB}$ in-FoV \\
\bottomrule
\end{tabular}
\end{center}

\textbf{What happens.}
The most aggressive compression: with $\text{CF} = 8$, the GNN targets $\approx 32$ clusters
of $\approx 8$ elements each.
Steering is at boresight (easiest case), so we can afford the compression.
This represents the maximum hardware cost reduction ($\sim32\times$ fewer RF chains
compared to element-level control).

\newpage
% ============================================================
\section{Summary}
% ============================================================

\begin{center}
\renewcommand{\arraystretch}{1.3}
\begin{tabular}{p{2.5cm} p{10.5cm}}
\toprule
\textbf{Input} & A $16 \times 16$ antenna array at $29.5\;\text{GHz}$ with specified
element spacing, beam steering direction, target clustering factor $\text{CF}_{\text{target}}$,
and SLL mask. \\
\midrule
\textbf{What we optimize} & The assignment of 256 antenna elements into $K$ clusters
(where $K$ is auto-discovered), such that the average cluster size matches the target
clustering factor, clusters are spatially contiguous, and the resulting far-field radiation
pattern meets the SLL requirements. \\
\midrule
\textbf{How} & A 3-layer Graph Attention Network (GAT) with mutual coupling edge weights
outputs soft cluster assignments $\mathbf{Z}$, trained unsupervised by minimizing a
composite loss: coupling MinCut (group strongly-coupled elements),
clustering factor (target average cluster size),
entropy (confident assignments),
and contiguity (spatial compactness). \\
\midrule
\textbf{Output} & A cluster assignment vector $\mathbf{c} \in \{0,\dots,K{-}1\}^{256}$
where $K$ is automatically discovered,
and the resulting far-field radiation pattern with metrics:
boresight gain, HPBW, SLL (in/out of FoV), and cost function $C_m$. \\
\midrule
\textbf{Key result} & The physics-informed GNN discovers the optimal number of clusters
to achieve the target clustering factor while respecting mutual coupling structure
and spatial contiguity. \\
\bottomrule
\end{tabular}
\end{center}

\end{document}
