{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Antenna Clustering Optimization - Comparison\n",
    "\n",
    "Questo notebook confronta l'algoritmo originale Monte Carlo con la versione ottimizzata.\n",
    "\n",
    "**Ottimizzazioni implementate:**\n",
    "1. Greedy initialization (iterazioni 1-10)\n",
    "2. Local search refinement\n",
    "3. Adaptive probability sampling (iterazioni 51+)\n",
    "4. NumPy vectorization nel kernel computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup e Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installa dipendenze se su Colab\n",
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "    print(\"Running on Colab - installing dependencies...\")\n",
    "    !pip install numpy scipy matplotlib -q\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "from scipy.interpolate import griddata\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Import completati!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Definizione Classi di Configurazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class LatticeConfig:\n",
    "    \"\"\"Configurazione lattice array\"\"\"\n",
    "    Nz: int  # Number of rows\n",
    "    Ny: int  # Number of columns\n",
    "    dist_z: float  # antenna distance on z axis [times lambda]\n",
    "    dist_y: float  # antenna distance on y axis [times lambda]\n",
    "    lattice_type: int = 1  # 1=Rectangular\n",
    "\n",
    "@dataclass\n",
    "class SystemConfig:\n",
    "    \"\"\"Parametri sistema\"\"\"\n",
    "    freq: float  # [Hz]\n",
    "    lambda_: float = field(init=False)\n",
    "    beta: float = field(init=False)\n",
    "    azi0: float = 0.0\n",
    "    ele0: float = 0.0\n",
    "    dele: float = 0.5\n",
    "    dazi: float = 0.5\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.lambda_ = 3e8 / self.freq\n",
    "        self.beta = 2 * np.pi / self.lambda_\n",
    "\n",
    "@dataclass\n",
    "class MaskConfig:\n",
    "    \"\"\"Parametri maschera SLL\"\"\"\n",
    "    elem: float = 30.0\n",
    "    azim: float = 60.0\n",
    "    SLL_level: float = 20.0\n",
    "    SLLin: float = 15.0\n",
    "\n",
    "@dataclass\n",
    "class ElementPatternConfig:\n",
    "    \"\"\"Configurazione pattern elemento\"\"\"\n",
    "    P: int = 1\n",
    "    Gel: float = 5.0\n",
    "    load_file: int = 0\n",
    "\n",
    "@dataclass\n",
    "class SimulationConfig:\n",
    "    \"\"\"Parametri simulazione\"\"\"\n",
    "    Niter: int = 1000\n",
    "    Cost_thr: int = 1000\n",
    "\n",
    "@dataclass\n",
    "class ClusterConfig:\n",
    "    \"\"\"Configurazione cluster\"\"\"\n",
    "    Cluster_type: List[np.ndarray] = field(default_factory=list)\n",
    "    rotation_cluster: int = 0\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if not self.Cluster_type:\n",
    "            self.Cluster_type = [np.array([[0, 0], [0, 1]])]\n",
    "\n",
    "print(\"Classi di configurazione definite!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Classe AntennaArray (con ottimizzazioni kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AntennaArray:\n",
    "    \"\"\"Classe per array di antenne con clustering\"\"\"\n",
    "\n",
    "    def __init__(self, lattice: LatticeConfig, system: SystemConfig, \n",
    "                 mask: MaskConfig, eef_config: Optional[ElementPatternConfig] = None):\n",
    "        self.lattice = lattice\n",
    "        self.system = system\n",
    "        self.mask = mask\n",
    "        self.eef_config = eef_config or ElementPatternConfig()\n",
    "        self.Nel = lattice.Nz * lattice.Ny\n",
    "\n",
    "        self._compute_lattice_vectors()\n",
    "        self._generate_lattice()\n",
    "        self._generate_polar_coordinates()\n",
    "        self._generate_element_pattern()\n",
    "        self._generate_mask()\n",
    "\n",
    "    def _compute_lattice_vectors(self):\n",
    "        lambda_ = self.system.lambda_\n",
    "        dz = self.lattice.dist_z * lambda_\n",
    "        dy = self.lattice.dist_y * lambda_\n",
    "        self.x1 = np.array([dy, 0.0])\n",
    "        self.x2 = np.array([0.0, dz])\n",
    "\n",
    "    def _generate_lattice(self):\n",
    "        Nz = self.lattice.Nz\n",
    "        Ny = self.lattice.Ny\n",
    "\n",
    "        if Nz % 2 == 1:\n",
    "            M = np.arange(-(Nz - 1) / 2, (Nz - 1) / 2 + 1)\n",
    "        else:\n",
    "            M = np.arange(-Nz / 2 + 1, Nz / 2 + 1)\n",
    "\n",
    "        if Ny % 2 == 1:\n",
    "            N = np.arange(-(Ny - 1) / 2, (Ny - 1) / 2 + 1)\n",
    "        else:\n",
    "            N = np.arange(-Ny / 2 + 1, Ny / 2 + 1)\n",
    "\n",
    "        self.NN, self.MM = np.meshgrid(N, M)\n",
    "        dz = self.x2[1]\n",
    "        dy = self.x1[0]\n",
    "        DELTA = max(self.x2[0], self.x1[1])\n",
    "\n",
    "        self.Y = self.NN * dy\n",
    "        self.Z = self.MM * dz\n",
    "        self.Y[1::2, :] = self.Y[1::2, :] + DELTA\n",
    "\n",
    "        self.Dz = np.max(self.Z) - np.min(self.Z)\n",
    "        self.Dy = np.max(self.Y) - np.min(self.Y)\n",
    "        self.Dy_total = self.Dy + self.x1[0]\n",
    "        self.Dz_total = self.Dz + self.x2[1]\n",
    "        self.ArrayMask = np.ones_like(self.Y)\n",
    "\n",
    "    def _generate_polar_coordinates(self):\n",
    "        beta = self.system.beta\n",
    "        lambda_ = self.system.lambda_\n",
    "\n",
    "        self.ele = np.arange(-90, 90 + self.system.dele, self.system.dele)\n",
    "        self.azi = np.arange(-90, 90 + self.system.dazi, self.system.dazi)\n",
    "        self.AZI, self.ELE = np.meshgrid(self.azi, self.ele)\n",
    "\n",
    "        self.WWae = beta * np.cos(np.deg2rad(90 - self.ELE))\n",
    "        self.Vvae = beta * np.sin(np.deg2rad(90 - self.ELE)) * np.sin(np.deg2rad(self.AZI))\n",
    "\n",
    "        chi = 2\n",
    "        self.Nw = int(np.floor(chi * 4 * self.Dz_total / lambda_))\n",
    "        self.Nv = int(np.floor(chi * 4 * self.Dy_total / lambda_))\n",
    "\n",
    "        ww = np.linspace(0, beta, self.Nw + 1)\n",
    "        self.ww = np.concatenate([-np.flip(ww[1:]), ww])\n",
    "        vv = np.linspace(0, beta, self.Nv + 1)\n",
    "        self.vv = np.concatenate([-np.flip(vv[1:]), vv])\n",
    "\n",
    "        self.WW, self.VV = np.meshgrid(self.ww, self.vv)\n",
    "\n",
    "        WW_clipped = np.clip(self.WW / beta, -1, 1)\n",
    "        self.ELEi = 90 - np.rad2deg(np.arccos(WW_clipped))\n",
    "\n",
    "        denom = beta * np.sin(np.deg2rad(90 - self.ELEi))\n",
    "        with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "            ratio = np.clip(self.VV / denom, -1, 1)\n",
    "            self.AZIi = np.real(np.rad2deg(np.arcsin(ratio)))\n",
    "\n",
    "        self.AZIi[self.Nv, :] = 0\n",
    "        self.AZIi[self.Nv, 0] = 90\n",
    "        self.AZIi[self.Nv, -1] = 90\n",
    "\n",
    "    def _generate_element_pattern(self):\n",
    "        P = self.eef_config.P\n",
    "        Gel = self.eef_config.Gel\n",
    "\n",
    "        if P == 0:\n",
    "            self.Fel = np.ones_like(self.ELE)\n",
    "        else:\n",
    "            self.Fel = (np.cos(np.deg2rad(self.ELE * 0.9)) * np.cos(np.deg2rad(self.AZI * 0.9))) ** P\n",
    "\n",
    "        if P == 0:\n",
    "            self.Fel_VW = np.ones_like(self.ELEi)\n",
    "        else:\n",
    "            self.Fel_VW = (np.cos(np.deg2rad(self.ELEi * 0.9)) * np.cos(np.deg2rad(self.AZIi * 0.9))) ** P\n",
    "\n",
    "        self.RPE = 20 * np.log10(np.abs(self.Fel) + 1e-10)\n",
    "        self.RPE_ele_max = np.max(self.RPE) + Gel\n",
    "        self.G_boresight = self.RPE_ele_max + 10 * np.log10(self.Nel)\n",
    "\n",
    "    def _generate_mask(self):\n",
    "        ele0 = self.system.ele0\n",
    "        azi0 = self.system.azi0\n",
    "        elem = self.mask.elem\n",
    "        azim = self.mask.azim\n",
    "        SLL_level = self.mask.SLL_level\n",
    "        SLLin = self.mask.SLLin\n",
    "\n",
    "        ele_cond = np.abs(self.ELE - ele0) <= elem\n",
    "        azi_cond = np.abs(self.AZI - azi0) <= azim\n",
    "\n",
    "        self.in_fov_mask = ele_cond & azi_cond\n",
    "        self.out_fov_mask = ~self.in_fov_mask\n",
    "\n",
    "        self.Mask_EA = np.full_like(self.ELE, self.G_boresight - SLL_level, dtype=float)\n",
    "        self.Mask_EA[self.in_fov_mask] = self.G_boresight - SLLin\n",
    "\n",
    "    def index_to_position_cluster(self, Cluster: List[np.ndarray], \n",
    "                                   ElementExc: Optional[np.ndarray] = None):\n",
    "        if ElementExc is None:\n",
    "            ElementExc = np.ones((self.lattice.Nz, self.lattice.Ny))\n",
    "\n",
    "        Ntrans = len(Cluster)\n",
    "        max_Lsub = max(c.shape[0] for c in Cluster)\n",
    "\n",
    "        Yc = np.full((max_Lsub, Ntrans), np.nan)\n",
    "        Zc = np.full((max_Lsub, Ntrans), np.nan)\n",
    "        Ac = np.full((max_Lsub, Ntrans), np.nan)\n",
    "\n",
    "        min_NN = int(np.min(self.NN))\n",
    "        min_MM = int(np.min(self.MM))\n",
    "\n",
    "        for kk, cluster in enumerate(Cluster):\n",
    "            for l1 in range(cluster.shape[0]):\n",
    "                Iy = int(cluster[l1, 0] - min_NN)\n",
    "                Iz = int(cluster[l1, 1] - min_MM)\n",
    "                Yc[l1, kk] = self.Y[Iz, Iy]\n",
    "                Zc[l1, kk] = self.Z[Iz, Iy]\n",
    "                Ac[l1, kk] = ElementExc[Iz, Iy]\n",
    "\n",
    "        return Yc, Zc, Ac\n",
    "\n",
    "    def coefficient_evaluation(self, Zc_m: np.ndarray, Yc_m: np.ndarray, Lsub: np.ndarray):\n",
    "        beta = self.system.beta\n",
    "        ele0 = self.system.ele0\n",
    "        azi0 = self.system.azi0\n",
    "\n",
    "        v0 = beta * np.sin(np.deg2rad(90 - ele0)) * np.sin(np.deg2rad(azi0))\n",
    "        w0 = beta * np.cos(np.deg2rad(90 - ele0))\n",
    "        Phase_m = np.exp(-1j * (w0 * Zc_m + v0 * Yc_m))\n",
    "        Amplit_m = 1.0 / Lsub\n",
    "        c0 = Amplit_m * Phase_m\n",
    "        return c0\n",
    "\n",
    "    def kernel1_rpe(self, Lsub: np.ndarray, Ac: np.ndarray, \n",
    "                    Yc: np.ndarray, Zc: np.ndarray, c0: np.ndarray):\n",
    "        Ntrans = len(Lsub)\n",
    "\n",
    "        # OPT: Cache flattened arrays\n",
    "        if not hasattr(self, '_VV_flat'):\n",
    "            self._VV_flat = self.VV.flatten()\n",
    "            self._WW_flat = self.WW.flatten()\n",
    "            self._Fel_VW_flat = self.Fel_VW.flatten()\n",
    "\n",
    "        VV_flat = self._VV_flat\n",
    "        WW_flat = self._WW_flat\n",
    "        Fel_VW_flat = self._Fel_VW_flat\n",
    "        Npoints = len(VV_flat)\n",
    "\n",
    "        # OPT: Vectorized kernel computation\n",
    "        all_Y = []\n",
    "        all_Z = []\n",
    "        cluster_indices = []\n",
    "\n",
    "        for kk in range(Ntrans):\n",
    "            Lsub_k = int(Lsub[kk])\n",
    "            for jj in range(Lsub_k):\n",
    "                if not np.isnan(Yc[jj, kk]) and not np.isnan(Zc[jj, kk]):\n",
    "                    all_Y.append(Yc[jj, kk])\n",
    "                    all_Z.append(Zc[jj, kk])\n",
    "                    cluster_indices.append(kk)\n",
    "\n",
    "        all_Y = np.array(all_Y)\n",
    "        all_Z = np.array(all_Z)\n",
    "        cluster_indices = np.array(cluster_indices)\n",
    "\n",
    "        # OPT: Compute all phases at once using broadcasting\n",
    "        phases = np.exp(1j * (np.outer(VV_flat, all_Y) + np.outer(WW_flat, all_Z)))\n",
    "        phases = phases * Fel_VW_flat[:, np.newaxis]\n",
    "\n",
    "        # OPT: Sum contributions using np.add.at\n",
    "        KerFF_sub = np.zeros((Npoints, Ntrans), dtype=complex)\n",
    "        np.add.at(KerFF_sub.T, cluster_indices, phases.T)\n",
    "\n",
    "        FF = KerFF_sub @ c0.T\n",
    "        FF_norm = FF / (np.max(np.abs(FF)) + 1e-10)\n",
    "        FF_norm_2D = FF_norm.reshape(self.VV.shape)\n",
    "        FF_norm_dB = 20 * np.log10(np.abs(FF_norm_2D) + 1e-10)\n",
    "\n",
    "        # OPT: Cache interpolation setup\n",
    "        if not hasattr(self, '_interp_points'):\n",
    "            self._interp_points = np.column_stack([WW_flat, VV_flat])\n",
    "            self._interp_xi = np.column_stack([self.WWae.flatten(), self.Vvae.flatten()])\n",
    "\n",
    "        values = FF_norm_dB.flatten()\n",
    "        FF_I_dB_flat = griddata(self._interp_points, values, self._interp_xi, \n",
    "                                 method=\"linear\", fill_value=-100)\n",
    "        FF_I_dB = FF_I_dB_flat.reshape(self.WWae.shape)\n",
    "\n",
    "        Nel_active = np.sum(Lsub)\n",
    "        FF_I_dB = FF_I_dB + self.RPE_ele_max + 10 * np.log10(Nel_active)\n",
    "\n",
    "        return FF_norm_dB, FF_I_dB, KerFF_sub, np.abs(FF_norm_2D) ** 2\n",
    "\n",
    "    def compute_cost_function(self, FF_I_dB: np.ndarray) -> int:\n",
    "        Constr = FF_I_dB - self.Mask_EA\n",
    "        Cm = np.sum(Constr > 0)\n",
    "        return int(Cm)\n",
    "\n",
    "    def compute_sll(self, FF_I_dB: np.ndarray):\n",
    "        sll_out_values = FF_I_dB[self.out_fov_mask]\n",
    "        sll_out = np.max(sll_out_values) if len(sll_out_values) > 0 else -100\n",
    "\n",
    "        sll_in_values = FF_I_dB[self.in_fov_mask]\n",
    "        if len(sll_in_values) > 0:\n",
    "            max_val = np.max(sll_in_values)\n",
    "            sll_in = np.max(sll_in_values[sll_in_values < max_val - 0.1]) if np.any(sll_in_values < max_val - 0.1) else max_val\n",
    "        else:\n",
    "            sll_in = -100\n",
    "\n",
    "        return sll_in, sll_out\n",
    "\n",
    "    def evaluate_clustering(self, Cluster: List[np.ndarray], \n",
    "                            ElementExc: Optional[np.ndarray] = None) -> Dict:\n",
    "        if ElementExc is None:\n",
    "            ElementExc = np.ones((self.lattice.Nz, self.lattice.Ny))\n",
    "\n",
    "        Yc, Zc, Ac = self.index_to_position_cluster(Cluster, ElementExc)\n",
    "        Ntrans = len(Cluster)\n",
    "\n",
    "        Lsub = np.array([c.shape[0] for c in Cluster])\n",
    "        Zc_m = np.array([np.nanmean(Zc[:Lsub[k], k]) for k in range(Ntrans)])\n",
    "        Yc_m = np.array([np.nanmean(Yc[:Lsub[k], k]) for k in range(Ntrans)])\n",
    "\n",
    "        c0 = self.coefficient_evaluation(Zc_m, Yc_m, Lsub)\n",
    "        FF_norm_dB, FF_I_dB, KerFF_sub, FF_norm = self.kernel1_rpe(Lsub, Ac, Yc, Zc, c0)\n",
    "\n",
    "        Cm = self.compute_cost_function(FF_I_dB)\n",
    "        sll_in, sll_out = self.compute_sll(FF_I_dB)\n",
    "\n",
    "        max_idx = np.unravel_index(np.argmax(FF_I_dB), FF_I_dB.shape)\n",
    "        theta_max = self.ele[max_idx[0]]\n",
    "        phi_max = self.azi[max_idx[1]]\n",
    "\n",
    "        Iele = np.argmin(np.abs(self.ele - self.system.ele0))\n",
    "        Iazi = np.argmin(np.abs(self.azi - self.system.azi0))\n",
    "\n",
    "        G_boresight = self.RPE_ele_max + 10 * np.log10(np.sum(Lsub))\n",
    "        SL_maxpointing = G_boresight - FF_I_dB[max_idx]\n",
    "        SL_theta_phi = G_boresight - FF_I_dB[Iele, Iazi]\n",
    "\n",
    "        return {\n",
    "            \"Yc\": Yc, \"Zc\": Zc, \"Ac\": Ac, \"Yc_m\": Yc_m, \"Zc_m\": Zc_m,\n",
    "            \"Lsub\": Lsub, \"Ntrans\": Ntrans, \"c0\": c0,\n",
    "            \"FF_norm_dB\": FF_norm_dB, \"FF_I_dB\": FF_I_dB, \"KerFF_sub\": KerFF_sub,\n",
    "            \"Cm\": Cm, \"sll_in\": sll_in, \"sll_out\": sll_out,\n",
    "            \"theta_max\": theta_max, \"phi_max\": phi_max,\n",
    "            \"SL_maxpointing\": SL_maxpointing, \"SL_theta_phi\": SL_theta_phi,\n",
    "            \"G_boresight\": G_boresight,\n",
    "        }\n",
    "\n",
    "print(\"Classe AntennaArray definita!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Classe per generazione Subarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullSubarraySetGeneration:\n",
    "    \"\"\"Genera il set completo di subarray possibili\"\"\"\n",
    "\n",
    "    def __init__(self, cluster_type: np.ndarray, lattice: LatticeConfig,\n",
    "                 NN: np.ndarray, MM: np.ndarray, rotation_cluster: int = 0):\n",
    "        self.cluster_type = np.atleast_2d(cluster_type)\n",
    "        self.lattice = lattice\n",
    "        self.NN = NN\n",
    "        self.MM = MM\n",
    "        self.rotation_cluster = rotation_cluster\n",
    "        self.S, self.Nsub = self._generate()\n",
    "\n",
    "    def _generate(self):\n",
    "        B = self.cluster_type\n",
    "        A = np.sum(B, axis=0)\n",
    "        M = self.MM.flatten()\n",
    "        N = self.NN.flatten()\n",
    "\n",
    "        if A[0] == 0:\n",
    "            step_M = B.shape[0]\n",
    "            step_N = 1\n",
    "        elif A[1] == 0:\n",
    "            step_N = B.shape[0]\n",
    "            step_M = 1\n",
    "        else:\n",
    "            step_M = 1\n",
    "            step_N = 1\n",
    "\n",
    "        S = []\n",
    "        min_M, max_M = int(np.min(M)), int(np.max(M))\n",
    "        min_N, max_N = int(np.min(N)), int(np.max(N))\n",
    "\n",
    "        for kk in range(min_M, max_M + 1, step_M):\n",
    "            for hh in range(min_N, max_N + 1, step_N):\n",
    "                Bshift = B.copy()\n",
    "                Bshift[:, 0] = B[:, 0] + hh\n",
    "                Bshift[:, 1] = B[:, 1] + kk\n",
    "\n",
    "                check = not np.any(\n",
    "                    (Bshift[:, 0] > max_N) | (Bshift[:, 0] < min_N) |\n",
    "                    (Bshift[:, 1] > max_M) | (Bshift[:, 1] < min_M)\n",
    "                )\n",
    "\n",
    "                if check:\n",
    "                    S.append(Bshift)\n",
    "\n",
    "        return S, len(S)\n",
    "\n",
    "print(\"Classe FullSubarraySetGeneration definita!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Classe Optimizer (con tutte le ottimizzazioni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IrregularClusteringMonteCarlo:\n",
    "    \"\"\"Ottimizzazione clustering con approccio Monte Carlo + ottimizzazioni\"\"\"\n",
    "\n",
    "    def __init__(self, array: AntennaArray, cluster_config: ClusterConfig,\n",
    "                 sim_config: SimulationConfig):\n",
    "        self.array = array\n",
    "        self.cluster_config = cluster_config\n",
    "        self.sim_config = sim_config\n",
    "\n",
    "        self.S_all = []\n",
    "        self.N_all = []\n",
    "        self.L = []\n",
    "\n",
    "        for bb, cluster_type in enumerate(cluster_config.Cluster_type):\n",
    "            gen = FullSubarraySetGeneration(\n",
    "                cluster_type, array.lattice, array.NN, array.MM,\n",
    "                cluster_config.rotation_cluster\n",
    "            )\n",
    "            self.S_all.append(gen.S)\n",
    "            self.N_all.append(gen.Nsub)\n",
    "            self.L.append(cluster_type.shape[0])\n",
    "\n",
    "        self.simulation = []\n",
    "        self.all_Cm = []\n",
    "        self.all_Ntrans = []\n",
    "        self.all_Nel = []\n",
    "\n",
    "        # OPT: Adaptive probability tracking\n",
    "        self.total_clusters = sum(self.N_all)\n",
    "        self._cluster_scores = np.ones(self.total_clusters)\n",
    "        self._selection_counts = np.ones(self.total_clusters)\n",
    "\n",
    "    def _select_random_clusters(self):\n",
    "        \"\"\"Selezione random originale (probabilità 50%)\"\"\"\n",
    "        selected_clusters = []\n",
    "        selected_rows = []\n",
    "\n",
    "        for bb, S in enumerate(self.S_all):\n",
    "            Nsub = self.N_all[bb]\n",
    "            selection = np.random.randint(0, 2, size=Nsub)\n",
    "            selected_rows.append(selection)\n",
    "            for idx in np.where(selection == 1)[0]:\n",
    "                selected_clusters.append(S[idx])\n",
    "\n",
    "        return selected_clusters, np.concatenate(selected_rows)\n",
    "\n",
    "    def _select_adaptive_clusters(self):\n",
    "        \"\"\"OPT: Selezione con probabilità adattiva\"\"\"\n",
    "        selected_clusters = []\n",
    "        selected_rows = []\n",
    "\n",
    "        probs = self._cluster_scores / self._selection_counts\n",
    "        probs = np.clip(probs, 0.1, 0.9)\n",
    "\n",
    "        offset = 0\n",
    "        for bb, S in enumerate(self.S_all):\n",
    "            Nsub = self.N_all[bb]\n",
    "            cluster_probs = probs[offset : offset + Nsub]\n",
    "            selection = (np.random.random(Nsub) < cluster_probs).astype(int)\n",
    "            selected_rows.append(selection)\n",
    "            for idx in np.where(selection == 1)[0]:\n",
    "                selected_clusters.append(S[idx])\n",
    "            offset += Nsub\n",
    "\n",
    "        return selected_clusters, np.concatenate(selected_rows)\n",
    "\n",
    "    def _update_adaptive_scores(self, selected_rows: np.ndarray, Cm: int):\n",
    "        \"\"\"OPT: Aggiorna score adattivi\"\"\"\n",
    "        reward = max(0, self.sim_config.Cost_thr - Cm) / self.sim_config.Cost_thr\n",
    "        indices = np.where(selected_rows == 1)[0]\n",
    "        self._cluster_scores[indices] += reward\n",
    "        self._selection_counts[indices] += 1\n",
    "\n",
    "    def _greedy_initialization(self, max_clusters: int = None):\n",
    "        \"\"\"OPT: Inizializzazione greedy\"\"\"\n",
    "        if max_clusters is None:\n",
    "            max_clusters = self.total_clusters // 2\n",
    "\n",
    "        all_clusters = []\n",
    "        cluster_to_flat_idx = []\n",
    "        offset = 0\n",
    "        for bb, S in enumerate(self.S_all):\n",
    "            for idx, cluster in enumerate(S):\n",
    "                all_clusters.append(cluster)\n",
    "                cluster_to_flat_idx.append(offset + idx)\n",
    "            offset += self.N_all[bb]\n",
    "\n",
    "        covered_elements = set()\n",
    "        selected_flat_indices = []\n",
    "\n",
    "        available_indices = list(range(len(all_clusters)))\n",
    "        np.random.shuffle(available_indices)\n",
    "\n",
    "        for idx in available_indices:\n",
    "            if len(selected_flat_indices) >= max_clusters:\n",
    "                break\n",
    "            cluster = all_clusters[idx]\n",
    "            cluster_elements = set(tuple(pos) for pos in cluster)\n",
    "            overlap = cluster_elements & covered_elements\n",
    "            if len(overlap) == 0:\n",
    "                selected_flat_indices.append(cluster_to_flat_idx[idx])\n",
    "                covered_elements.update(cluster_elements)\n",
    "\n",
    "        selected_rows = np.zeros(self.total_clusters, dtype=int)\n",
    "        selected_rows[selected_flat_indices] = 1\n",
    "\n",
    "        selected_clusters = []\n",
    "        offset = 0\n",
    "        for bb, S in enumerate(self.S_all):\n",
    "            Nsub = self.N_all[bb]\n",
    "            for idx in range(Nsub):\n",
    "                if selected_rows[offset + idx] == 1:\n",
    "                    selected_clusters.append(S[idx])\n",
    "            offset += Nsub\n",
    "\n",
    "        return selected_clusters, selected_rows\n",
    "\n",
    "    def _rows_to_clusters(self, selected_rows: np.ndarray):\n",
    "        \"\"\"OPT: Converte array selezione in lista cluster\"\"\"\n",
    "        clusters = []\n",
    "        offset = 0\n",
    "        for bb, S in enumerate(self.S_all):\n",
    "            Nsub = self.N_all[bb]\n",
    "            for idx in range(Nsub):\n",
    "                if selected_rows[offset + idx] == 1:\n",
    "                    clusters.append(S[idx])\n",
    "            offset += Nsub\n",
    "        return clusters\n",
    "\n",
    "    def _local_search(self, selected_rows: np.ndarray, current_Cm: int, \n",
    "                      max_iterations: int = 50):\n",
    "        \"\"\"OPT: Local search per raffinamento\"\"\"\n",
    "        best_rows = selected_rows.copy()\n",
    "        best_Cm = current_Cm\n",
    "\n",
    "        for _ in range(max_iterations):\n",
    "            improved = False\n",
    "            indices_to_try = np.random.permutation(self.total_clusters)[:min(20, self.total_clusters)]\n",
    "\n",
    "            for idx in indices_to_try:\n",
    "                candidate_rows = best_rows.copy()\n",
    "                candidate_rows[idx] = 1 - candidate_rows[idx]\n",
    "                clusters = self._rows_to_clusters(candidate_rows)\n",
    "                if len(clusters) == 0:\n",
    "                    continue\n",
    "\n",
    "                result = self.array.evaluate_clustering(clusters)\n",
    "                candidate_Cm = result[\"Cm\"]\n",
    "\n",
    "                if candidate_Cm < best_Cm:\n",
    "                    best_rows = candidate_rows\n",
    "                    best_Cm = candidate_Cm\n",
    "                    improved = True\n",
    "                    break\n",
    "\n",
    "            if not improved:\n",
    "                break\n",
    "\n",
    "        return best_rows, best_Cm\n",
    "\n",
    "    def run(self, verbose: bool = True, use_optimizations: bool = True) -> Dict:\n",
    "        \"\"\"Esegue ottimizzazione\"\"\"\n",
    "        start_time = time.time()\n",
    "\n",
    "        if verbose:\n",
    "            print(\"=\" * 60)\n",
    "            print(\"IRREGULAR CLUSTERING - MONTE CARLO OPTIMIZATION\")\n",
    "            if use_optimizations:\n",
    "                print(\"  [OPTIMIZED MODE: greedy init + local search + adaptive]\")\n",
    "            else:\n",
    "                print(\"  [ORIGINAL MODE: random sampling only]\")\n",
    "            print(\"=\" * 60)\n",
    "            print(f\"Array: {self.array.lattice.Nz}x{self.array.lattice.Ny} = {self.array.Nel} elementi\")\n",
    "            print(f\"Iterazioni: {self.sim_config.Niter}\")\n",
    "            print(\"=\" * 60)\n",
    "\n",
    "        sss = 0\n",
    "        best_Cm_so_far = float(\"inf\")\n",
    "\n",
    "        for ij_cont in range(1, self.sim_config.Niter + 1):\n",
    "            # Progress bar\n",
    "            if verbose and ij_cont % 10 == 0:\n",
    "                pct = (ij_cont / self.sim_config.Niter) * 100\n",
    "                print(f\"  [Progresso: {ij_cont}/{self.sim_config.Niter} ({pct:.0f}%) | Best Cm: {best_Cm_so_far:.0f}]\", end=\"\\r\")\n",
    "\n",
    "            # Selezione cluster\n",
    "            if use_optimizations and ij_cont <= 10:\n",
    "                if verbose and ij_cont == 1:\n",
    "                    print(\"  >> Fase 1: Greedy initialization (iter 1-10)\")\n",
    "                Cluster, selected_rows = self._greedy_initialization()\n",
    "            elif use_optimizations and ij_cont == 11:\n",
    "                if verbose:\n",
    "                    print(\"\\n  >> Fase 2: Random sampling (iter 11-50)\")\n",
    "                Cluster, selected_rows = self._select_random_clusters()\n",
    "            elif use_optimizations and ij_cont == 51:\n",
    "                if verbose:\n",
    "                    print(\"\\n  >> Fase 3: Adaptive sampling (iter 51+)\")\n",
    "                Cluster, selected_rows = self._select_adaptive_clusters()\n",
    "            elif use_optimizations and ij_cont > 50:\n",
    "                Cluster, selected_rows = self._select_adaptive_clusters()\n",
    "            else:\n",
    "                Cluster, selected_rows = self._select_random_clusters()\n",
    "\n",
    "            if len(Cluster) == 0:\n",
    "                self.all_Cm.append(float(\"inf\"))\n",
    "                self.all_Ntrans.append(0)\n",
    "                self.all_Nel.append(0)\n",
    "                continue\n",
    "\n",
    "            result = self.array.evaluate_clustering(Cluster)\n",
    "            Cm = result[\"Cm\"]\n",
    "            Ntrans = result[\"Ntrans\"]\n",
    "            Nel_active = int(np.sum(result[\"Lsub\"]))\n",
    "\n",
    "            # Local search\n",
    "            if use_optimizations and Cm < self.sim_config.Cost_thr * 2:\n",
    "                old_Cm = Cm\n",
    "                selected_rows, Cm = self._local_search(selected_rows, Cm, max_iterations=30)\n",
    "                if verbose and Cm < old_Cm:\n",
    "                    print(f\"\\n  >> Local search: Cm {old_Cm} -> {Cm}\")\n",
    "                Cluster = self._rows_to_clusters(selected_rows)\n",
    "                if len(Cluster) > 0:\n",
    "                    result = self.array.evaluate_clustering(Cluster)\n",
    "                    Cm = result[\"Cm\"]\n",
    "                    Ntrans = result[\"Ntrans\"]\n",
    "                    Nel_active = int(np.sum(result[\"Lsub\"]))\n",
    "\n",
    "            if use_optimizations:\n",
    "                self._update_adaptive_scores(selected_rows, Cm)\n",
    "\n",
    "            self.all_Cm.append(Cm)\n",
    "            self.all_Ntrans.append(Ntrans)\n",
    "            self.all_Nel.append(Nel_active)\n",
    "\n",
    "            if Cm < best_Cm_so_far:\n",
    "                best_Cm_so_far = Cm\n",
    "\n",
    "            if Cm < self.sim_config.Cost_thr:\n",
    "                sss += 1\n",
    "                solution = {\n",
    "                    \"selected_rows\": selected_rows.copy(),\n",
    "                    \"Cm\": Cm,\n",
    "                    \"Ntrans\": Ntrans,\n",
    "                    \"Nel\": Nel_active,\n",
    "                    \"sll_in\": result[\"sll_in\"],\n",
    "                    \"sll_out\": result[\"sll_out\"],\n",
    "                    \"iteration\": ij_cont,\n",
    "                }\n",
    "                self.simulation.append(solution)\n",
    "\n",
    "        elapsed_time = time.time() - start_time\n",
    "\n",
    "        if verbose:\n",
    "            print(\"\\n\")\n",
    "            print(\"=\" * 60)\n",
    "            print(\"RISULTATI\")\n",
    "            print(\"=\" * 60)\n",
    "            print(f\"Iterazioni: {self.sim_config.Niter}\")\n",
    "            print(f\"Soluzioni valide: {len(self.simulation)}\")\n",
    "            print(f\"Tempo: {elapsed_time:.2f} s\")\n",
    "\n",
    "            if self.simulation:\n",
    "                best_sol = min(self.simulation, key=lambda x: x[\"Cm\"])\n",
    "                print(f\"\\nMIGLIORE SOLUZIONE:\")\n",
    "                print(f\"  Cm: {best_sol['Cm']}\")\n",
    "                print(f\"  Ntrans: {best_sol['Ntrans']}\")\n",
    "                print(f\"  Nel: {best_sol['Nel']}\")\n",
    "                print(f\"  SLL out: {best_sol['sll_out']:.2f} dB\")\n",
    "                print(f\"  SLL in: {best_sol['sll_in']:.2f} dB\")\n",
    "\n",
    "        return {\n",
    "            \"simulation\": self.simulation,\n",
    "            \"all_Cm\": self.all_Cm,\n",
    "            \"all_Ntrans\": self.all_Ntrans,\n",
    "            \"all_Nel\": self.all_Nel,\n",
    "            \"elapsed_time\": elapsed_time,\n",
    "            \"n_valid_solutions\": len(self.simulation),\n",
    "        }\n",
    "\n",
    "print(\"Classe IrregularClusteringMonteCarlo definita!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Configurazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametri configurabili\n",
    "NITER = 200  # Numero iterazioni (aumenta per risultati migliori)\n",
    "SEED = 42    # Random seed per riproducibilità\n",
    "\n",
    "# Configurazione array\n",
    "lattice = LatticeConfig(Nz=16, Ny=16, dist_z=0.6, dist_y=0.53, lattice_type=1)\n",
    "system = SystemConfig(freq=29.5e9, azi0=0, ele0=0, dele=0.5, dazi=0.5)\n",
    "mask = MaskConfig(elem=30, azim=60, SLL_level=20, SLLin=15)\n",
    "eef = ElementPatternConfig(P=1, Gel=5, load_file=0)\n",
    "cluster_config = ClusterConfig(Cluster_type=[np.array([[0, 0], [0, 1]])])\n",
    "sim_config = SimulationConfig(Niter=NITER, Cost_thr=1000)\n",
    "\n",
    "print(\"Configurazione:\")\n",
    "print(f\"  Array: {lattice.Nz}x{lattice.Ny} = {lattice.Nz * lattice.Ny} elementi\")\n",
    "print(f\"  Frequenza: {system.freq/1e9:.1f} GHz\")\n",
    "print(f\"  Iterazioni: {NITER}\")\n",
    "print(f\"  Cost threshold: {sim_config.Cost_thr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Inizializzazione Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Inizializzazione array antenna...\")\n",
    "array = AntennaArray(lattice, system, mask, eef)\n",
    "print(\"Array inizializzato!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Test ORIGINALE (senza ottimizzazioni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"TEST ALGORITMO ORIGINALE (use_optimizations=False)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "np.random.seed(SEED)\n",
    "optimizer_original = IrregularClusteringMonteCarlo(array, cluster_config, sim_config)\n",
    "results_original = optimizer_original.run(verbose=True, use_optimizations=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Test OTTIMIZZATO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"TEST ALGORITMO OTTIMIZZATO (use_optimizations=True)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "np.random.seed(SEED)\n",
    "optimizer_optimized = IrregularClusteringMonteCarlo(array, cluster_config, sim_config)\n",
    "results_optimized = optimizer_optimized.run(verbose=True, use_optimizations=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Confronto Risultati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"CONFRONTO RISULTATI\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def get_best(results):\n",
    "    if results[\"n_valid_solutions\"] == 0:\n",
    "        return None\n",
    "    return min(results[\"simulation\"], key=lambda x: x[\"Cm\"])\n",
    "\n",
    "best_orig = get_best(results_original)\n",
    "best_opt = get_best(results_optimized)\n",
    "\n",
    "print(f\"{'Metrica':<30} {'Originale':>15} {'Ottimizzato':>15}\")\n",
    "print(\"-\"*60)\n",
    "print(f\"{'Tempo esecuzione (s)':<30} {results_original['elapsed_time']:>15.2f} {results_optimized['elapsed_time']:>15.2f}\")\n",
    "print(f\"{'Soluzioni valide':<30} {results_original['n_valid_solutions']:>15} {results_optimized['n_valid_solutions']:>15}\")\n",
    "\n",
    "if best_orig and best_opt:\n",
    "    print(f\"{'Best Cm (lower=better)':<30} {best_orig['Cm']:>15} {best_opt['Cm']:>15}\")\n",
    "    print(f\"{'Best SLL out (dB)':<30} {best_orig['sll_out']:>15.2f} {best_opt['sll_out']:>15.2f}\")\n",
    "    print(f\"{'Best Ntrans':<30} {best_orig['Ntrans']:>15} {best_opt['Ntrans']:>15}\")\n",
    "    print(f\"{'Best Nel':<30} {best_orig['Nel']:>15} {best_opt['Nel']:>15}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Visualizzazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Cost function evolution\n",
    "axes[0].plot(results_original['all_Cm'], 'b-', alpha=0.7, label='Originale')\n",
    "axes[0].plot(results_optimized['all_Cm'], 'r-', alpha=0.7, label='Ottimizzato')\n",
    "axes[0].set_xlabel('Iterazione')\n",
    "axes[0].set_ylabel('Cost Function (Cm)')\n",
    "axes[0].set_title('Evoluzione Cost Function')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Histogram of Cm values\n",
    "cm_orig = [c for c in results_original['all_Cm'] if c != float('inf') and c < 5000]\n",
    "cm_opt = [c for c in results_optimized['all_Cm'] if c != float('inf') and c < 5000]\n",
    "axes[1].hist(cm_orig, bins=30, alpha=0.5, label='Originale', color='blue')\n",
    "axes[1].hist(cm_opt, bins=30, alpha=0.5, label='Ottimizzato', color='red')\n",
    "axes[1].set_xlabel('Cost Function (Cm)')\n",
    "axes[1].set_ylabel('Frequenza')\n",
    "axes[1].set_title('Distribuzione Cost Function')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Number of clusters\n",
    "axes[2].plot(results_original['all_Ntrans'], 'b-', alpha=0.7, label='Originale')\n",
    "axes[2].plot(results_optimized['all_Ntrans'], 'r-', alpha=0.7, label='Ottimizzato')\n",
    "axes[2].set_xlabel('Iterazione')\n",
    "axes[2].set_ylabel('Numero Cluster')\n",
    "axes[2].set_title('Numero di Cluster per Iterazione')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Conclusioni\n",
    "\n",
    "**Ottimizzazioni implementate:**\n",
    "1. **Greedy initialization** (iter 1-10): Costruisce soluzioni iniziali selezionando cluster non sovrapposti\n",
    "2. **Local search** (su soluzioni promettenti): Migliora flip-by-flip le soluzioni buone\n",
    "3. **Adaptive sampling** (iter 51+): I cluster che appaiono in buone soluzioni hanno maggiore probabilità\n",
    "4. **NumPy vectorization**: Kernel computation ottimizzato con operazioni vettoriali\n",
    "\n",
    "Ogni riga di codice ottimizzata ha un commento `OPT:` che spiega cosa fa."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
